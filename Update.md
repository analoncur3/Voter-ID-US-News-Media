## Updates

I thought I could write up here what I've been up to since we last met as its been a while. 
1. I first looked into getting urls via Mediacloud and retrieving stories using NewsPlease. I initially found some issues with this: A) There were discrepancies between the storyCount output, which gives the expected number of stories per query, and the actual urls retrieved. I initially thought this was due to the data issues Mediacloud has been experiencing. B) I checked the timeframes of the news media sources through their website and found some of them had stories until 2020 or before which isn't ideal.
2. Shortly after this we met and decided to try out getting stories through NexisUni. Unfortunately there aren't many news media sources there. The only relevant ones were *The New York Times* and *USA Today*, both left-leaning news media. I managed to retrieve text data from these articles using LexisUniTools in R, but experienced some issues trying to get rid of duplicates. It also became obvious that getting data from important right-wing media like Fox News and Breitbart would be difficult as neither has an API.
3. After this, I checked the [github repo](https://github.com/wlmwng/us-right-media) Damian sent me a while ago from Wai Lam, who gathered Mediacloud urls from relevant right-wing news media last year without using a specific query (including Fox News, Breitbart, Washington Examiner, among others) as I thought maybe an option would be maybe filter their already downloaded data with our query. When I checked their Python scripts on github, I found that they managed to retrieve stories beyond the timelines stated in the website which came as a (positive) surprise.
4. I got in touch with them to see if they had experienced similar issues downloading this data, in terms of finding differences between expected vs retrieved stories and to ask whether they had indeed found stories beyond the timelines specified in the Mediacloud website. In terms of the missing urls, they redirected me to this github [issue](https://github.com/mediacloud/backend/issues/664), explaining that duplicates are sometimes getting counted in the "x number of stories" metric but they are filtered out when actually retrieving them. In other words, the discrepancy could be because the workarounds/fixes haven't been evenly implemented yet to correctly calculate the number of stories (without duplicates) and not necessarily because of stories missing. This was a relief! They also confirmed they were able to get stories beyond the timelines stated in the Source Manager tab in the website as the documentation is not fully in-sync with what's in the database itself. 
5. I went back to checking Mediacloud to find out more about the missing data issues, to confirm the discrepancies I was finding werent because of actually missing data. According to their latest [blog](https://mediacloud.org/news/2022/3/4/media-cloud-tools-update-for-march-2022) update in March 7, the issues with missing data only affect data between September 25 - November 23, 2021 of some sources, and most stories after December 25, 2021. As they dont specify which sources or data are affected, I decided to give the Mediacloud API another go. 
6. Here I stopped to think about other news sources we could gather to have a bit more data. The initial choice of sources was inspired by X study, which split news sources by partisanship left, centre and right. To keep things consistent with the political elite study, I thought perhaps it made more sense to similarly split the corpus between right and left, as it would make comparisons easier between these 2 groups, but include more sources in each of these, instead of the 2 news sources per category initially proposed.
